{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Install Packages\n",
    "%pip install boto3\n",
    "%pip install pandas\n",
    "%pip install awscli\n",
    "\n",
    "import os\n",
    "import awscli\n",
    "import boto3\n",
    "import time\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "%env region=us-east-1\n",
    "\n",
    "#Create an S3 client for Python\n",
    "s3_client = boto3.client(\n",
    "    \"s3\",\n",
    "    region_name=os.environ['region'],\n",
    ")\n",
    "\n",
    "#Create an Athena client for Python\n",
    "athena = boto3.client(\n",
    "    'athena', \n",
    "    region_name=os.environ['region'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Athena client query\n",
    "athena_output_bucket = 's3://anelpere-duke-datathon-2024/team2/athena-output/'\n",
    "\n",
    "response = athena.start_query_execution(\n",
    "    QueryString=\"\"\"\n",
    "    SELECT category, text \n",
    "    FROM \"mimiciii\".\"noteevents\"\n",
    "    WHERE category = 'Discharge summary'\n",
    "    LIMIT 10\n",
    "    \"\"\",\n",
    "    QueryExecutionContext={\n",
    "        'Database': 'mimiciii'\n",
    "    },\n",
    "    ResultConfiguration={\n",
    "        'OutputLocation': athena_output_bucket\n",
    "    }\n",
    ")\n",
    "while True:\n",
    "    try:\n",
    "        # This function only loads the first 1000 rows\n",
    "        athena.get_query_results(\n",
    "            QueryExecutionId=response[\"QueryExecutionId\"]\n",
    "        )\n",
    "        break\n",
    "    except Exception as err:\n",
    "        if \"not yet finished\" in str(err):\n",
    "            time.sleep(0.001)\n",
    "        else:\n",
    "            raise err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retrieve Athena query results\n",
    "S3_BUCKET_NAME = \"anelpere-duke-datathon-2024\"\n",
    "S3_OUTPUT_DIRECTORY = \"team2/athena-output\"\n",
    "temp_file_location: str = \"athena_10_text_results.csv\"\n",
    "\n",
    "s3_client.download_file(\n",
    "    S3_BUCKET_NAME,\n",
    "    f\"{S3_OUTPUT_DIRECTORY}/{response['QueryExecutionId']}.csv\",\n",
    "    temp_file_location,\n",
    ")\n",
    "df = pd.read_csv(temp_file_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Format output data for analysis by Comprehend\n",
    "upload_bucket = \"s3://anelpere-duke-datathon-2024/team2/formatted/\"\n",
    "\n",
    "df = pd.read_csv('athena_10_text_results.csv')\n",
    "df = df.drop('category', axis=1)\n",
    "df.to_csv('athena_10_text_formatted.csv', index=False)\n",
    "\n",
    "#spliting rows into seperate files\n",
    "with open('athena_10_text_formatted.csv') as infile, open('output/output1.csv', 'w') as outfile:\n",
    "    reader = csv.reader(infile)\n",
    "    writer = csv.writer(outfile)\n",
    "    \n",
    "    header = next(reader)\n",
    "    writer.writerow(header)\n",
    "    \n",
    "    row = next(reader)\n",
    "    writer.writerow(row)\n",
    "\n",
    "    for i, row in enumerate(reader):\n",
    "        with open(f'output/output{i+2}.csv', 'w') as outfile:\n",
    "            reader = csv.reader(infile) # reopen file\n",
    "            writer = csv.writer(outfile)\n",
    "            writer.writerow(header)\n",
    "            writer.writerow(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Upload the files to S3\n",
    "upload_bucket = \"s3://anelpere-duke-datathon-2024/team2/formatted/\"\n",
    "upload_bucket_prefix = \"team2/formatted/.ipynb_checkpoints/\"\n",
    "local_dir = \"output/\"\n",
    "\n",
    "if os.environ.get('LC_CTYPE', '') == 'UTF-8':\n",
    "    os.environ['LC_CTYPE'] = 'en_US.UTF-8'\n",
    "\n",
    "from awscli.clidriver import create_clidriver\n",
    "driver = create_clidriver()\n",
    "driver.main('s3 sync output/    s3://anelpere-duke-datathon-2024/team2/formatted/'.split())\n",
    "\n",
    "#delete the checkpoint files\n",
    "keys = s3_client.list_objects_v2(Bucket=S3_BUCKET_NAME, Prefix=upload_bucket_prefix).get('Contents', [])  \n",
    "keys = [obj['Key'] for obj in keys]\n",
    "\n",
    "s3_client.delete_objects(Bucket=S3_BUCKET_NAME, Delete={'Objects': [{'Key': key} for key in keys]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comprehend medical detection\n",
    "comprehendmedical = boto3.client('comprehendmedical')\n",
    "\n",
    "job = comprehendmedical.start_icd10_cm_inference_job(\n",
    "    InputDataConfig={\n",
    "        'S3Bucket': S3_BUCKET_NAME,\n",
    "        'S3Key': 'team2/formatted'\n",
    "    },\n",
    "    OutputDataConfig={\n",
    "        'S3Bucket': 'anelpere-duke-datathon-2024',\n",
    "        'S3Key': 'team2/output'\n",
    "    },\n",
    "    DataAccessRoleArn='arn:aws:iam::610912512102:role/comprehend-medical-role',\n",
    "    JobName='Mimic-test-job',\n",
    "    LanguageCode='en'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
